{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ghost\\Anaconda3\\lib\\site-packages\\h5py\\__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1. train 2. eval\n",
      "2\n",
      "INFO:tensorflow:Restoring parameters from ./checkpoint/model.ckpt\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "[ True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True  True  True  True  True  True  True  True  True  True  True\n",
      "  True  True]\n",
      "total sample count: 500\n",
      "precision @ 1: 1.000000\n",
      "evaluation time: 0.240756 seconds\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import flags\n",
    "import image\n",
    "import sys\n",
    "import datetime\n",
    "import numpy as np\n",
    "\n",
    "FLAGS = tf.app.flags.FLAGS\n",
    "\n",
    "def weight_variable(shape) :\n",
    "    init = tf.truncated_normal(shape, stddev=1)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def bias_variable(shape) :\n",
    "    init = tf.constant(1,shape=shape)\n",
    "    return tf.Variable(init)\n",
    "\n",
    "def conv2d(x, W) :\n",
    "    return tf.nn.conv2d(x, W, strides=[1,1,1,1], padding='SAME')\n",
    "\n",
    "def max_pool(x, h, w) :\n",
    "    return tf.nn.max_pool(x, ksize=[1,h,w,1],strides=[1,h,w,1], padding='SAME')\n",
    "\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "#이미지 불러오기\n",
    "print(\"1. train 2. eval\")\n",
    "val = input()\n",
    "\n",
    "if val is '1':\n",
    "    images, labels = image.get_data('train',FLAGS.batch_size)\n",
    "else:\n",
    "    images, labels = image.get_data('eval', FLAGS.batch_size)\n",
    "\n",
    "\n",
    "\n",
    "#신경망구성\n",
    "pool_size = FLAGS.pool_size\n",
    "kernel_size = FLAGS.kernel_size\n",
    "channel = FLAGS.channel\n",
    "img_size = FLAGS.img_size\n",
    "\n",
    "# 첫번째 합성곱\n",
    "w1 = weight_variable([kernel_size,kernel_size,channel,img_size])\n",
    "b1 = bias_variable([img_size])\n",
    "L1 = tf.nn.relu(conv2d(images,w1)+ tf.cast(b1, tf.float32))\n",
    "L1 = max_pool(L1,pool_size,pool_size)\n",
    "#L1 = tf.nn.dropout(L1,keep_prob=keep_prob)\n",
    "\n",
    "prev_img_size = img_size\n",
    "img_size *= 2\n",
    "\n",
    "# 두번째 합성곱\n",
    "w2 = weight_variable([kernel_size,kernel_size,prev_img_size,img_size])\n",
    "b2 = bias_variable([img_size])\n",
    "L2 = tf.nn.relu(conv2d(L1,w2)+tf.cast(b2, tf.float32))\n",
    "L2 = max_pool(L2,pool_size,pool_size)\n",
    "\n",
    "prev_img_size = img_size\n",
    "img_size *= 2\n",
    "\n",
    "# 세번째 합성곱\n",
    "w3 = weight_variable([kernel_size,kernel_size,prev_img_size,img_size])\n",
    "b3 = bias_variable([img_size])\n",
    "L3 = tf.nn.relu(conv2d(L2,w3)+tf.cast(b3, tf.float32))\n",
    "L3 = max_pool(L3,pool_size,pool_size)\n",
    "\n",
    "fc_size = FLAGS.fc_size\n",
    "\n",
    "\n",
    "\n",
    "# full_connected, \n",
    "w_fc1 = weight_variable([16*16*128,fc_size])\n",
    "b_fc1 = bias_variable([fc_size])\n",
    "x_fc1 = tf.reshape(L3,[-1, 16*16*128])\n",
    "L_fc1 = tf.nn.relu(tf.matmul(x_fc1, w_fc1) +tf.cast(b_fc1, tf.float32))\n",
    "\n",
    "keep_prob = tf.placeholder(tf.float32)\n",
    "L_fc1 = tf.nn.dropout(L_fc1,keep_prob)\n",
    "\n",
    "w_fc2 = weight_variable([fc_size,2])\n",
    "b_fc2 = bias_variable([2])\n",
    "\n",
    "#hypothesis output\n",
    "y_conv = tf.matmul(L_fc1,w_fc2) +tf.cast(b_fc2, tf.float32) \n",
    "\n",
    "#cross entropy 정의 output\n",
    "cross_entropy = tf.reduce_mean(tf.nn.sparse_softmax_cross_entropy_with_logits\n",
    "                               (logits=y_conv, labels=labels))\n",
    "\n",
    "#train step 정의 output\n",
    "train_step = tf.train.AdamOptimizer(0.001).minimize(cross_entropy)\n",
    "\n",
    "#tensorboard 기록하기 위한 선언\n",
    "cost_sum = tf.summary.scalar(\"cost\", cross_entropy)\n",
    "\n",
    "#정확도 계산 변수 선언 y_conv와 Y의 각 행에서 가장 큰 값이 같은지 비교\n",
    "#correct_prediction = tf.equal(tf.argmax(y_conv,1),tf.argmax(Y,1))\n",
    "#accuracy = tf.reduce_mean(tf.cast(correct_prediction,tf.float32))\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.allow_growth = True\n",
    "\n",
    "\n",
    "#saver 이용해서 모델 저장 model 폴더에 저장한다.\n",
    "#SAVE_DIR = \"model\"\n",
    "#saver = tf.train.Saver()\n",
    "#checkpoint_path = os.path.join(SAVE_DIR,\"model\")\n",
    "#ckpt = tf.train.get_checkpoint_state(SAVE_DIR)\n",
    "if tf.gfile.Exists(FLAGS.checkpoint_dir) == False:\n",
    "    tf.gfile.MakeDirs(FLAGS.checkpoint_dir)\n",
    "\n",
    "if val is '1':\n",
    "    with tf.Session(config=config) as sess:\n",
    "        #print(\"학습 시작\")\n",
    "\n",
    "        #시작 시간 기록\n",
    "        \n",
    "\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        #if tf.gfile.Exists(FLAGS.checkpoint_dir + '/model.ckpt'):\n",
    "        #    saver.restore(sess, FLAGS.checkpoint_dir + '/model.ckpt')\n",
    "            \n",
    "        #else:\n",
    "        init = tf.global_variables_initializer()\n",
    "        sess.run(init)\n",
    "\n",
    "        #saver.restore(sess, FLAGS.checkpoint_dir + '/model.ckpt')\n",
    "        \n",
    "        writer = tf.summary.FileWriter(\"./logs/cost_log\")\n",
    "        writer.add_graph(sess.graph)  # Show the graph\n",
    "        merge_sum = tf.summary.merge_all()\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "        \n",
    "        for step in range(FLAGS.max_steps):\n",
    "\n",
    "            #sess.run(train_step, feed_dict={keep_prob: 0.7})\n",
    "            summary, _ = sess.run([merge_sum,train_step], feed_dict={keep_prob: 0.7})\n",
    "            writer.add_summary(summary, global_step=step)\n",
    "            print (step, sess.run(cross_entropy, feed_dict={keep_prob: 1.0}))\n",
    "\n",
    "            if step % 100 == 0 or (step + 1) == FLAGS.max_steps:\n",
    "                saver.save(sess, FLAGS.checkpoint_dir + '/model.ckpt')\n",
    "        print(\"Train is complete!\")\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "        \n",
    "        \n",
    "else:\n",
    "    with tf.Session(config=config) as sess:\n",
    "        saver = tf.train.Saver()\n",
    "        \n",
    "        #if tf.gfile.Exists(FLAGS.checkpoint_dir + '/model.ckpt'):\n",
    "         #   saver.restore(sess, FLAGS.checkpoint_dir + '/model.ckpt')\n",
    "         #   print('Open Complete')\n",
    "        #else:\n",
    "        #    print('Cannot find save file')\n",
    "        \n",
    "        saver.restore(sess, FLAGS.checkpoint_dir + '/model.ckpt')\n",
    "        \n",
    "        delta = datetime.timedelta()\n",
    "        max_steps = 10\n",
    "        true_count = 0.\n",
    "        total_sample_count = max_steps * FLAGS.batch_size\n",
    "        \n",
    "        top_k_op = tf.nn.in_top_k(y_conv, labels, 1)\n",
    "        coord = tf.train.Coordinator()\n",
    "        threads = tf.train.start_queue_runners(sess=sess,coord=coord)\n",
    "\n",
    "        for i in range(0, max_steps):\n",
    "            start = datetime.datetime.now()\n",
    "            predictions = sess.run(top_k_op, feed_dict={keep_prob: 1.0})\n",
    "            print(predictions)\n",
    "            true_count += np.sum(predictions)\n",
    "            delta += datetime.datetime.now() - start\n",
    "        coord.request_stop()\n",
    "        coord.join(threads)\n",
    "    print ('total sample count: %d' % total_sample_count)\n",
    "\n",
    "    print ('precision @ 1: %f' % (true_count / total_sample_count))\n",
    "\n",
    "    print ('evaluation time: %f seconds' % ((delta.seconds + delta.microseconds / 1E6) / max_steps))\n",
    "        \n",
    "#h_conv1 = tf.nn.relu(conv2d(x_image, W_conv1) + b_conv1)\n",
    "#h_pool1 = max_pool_2x2(h_conv1)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
